{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cifar-10_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"8ZfxTMasEczG","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import print_function\n","import keras\n","from keras import metrics\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1tMYN3ZeEcz6","colab_type":"code","colab":{}},"cell_type":"code","source":["#base setup\n","batch_size = 64\n","num_classes = 10\n","epochs = 5\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y7HFqheTEc0b","colab_type":"code","outputId":"6ff395d0-2bba-4fc6-90c4-ebd0940103fc","executionInfo":{"status":"ok","timestamp":1548976426898,"user_tz":300,"elapsed":104,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"metadata":{"id":"lpuBv5QEEc1b","colab_type":"code","colab":{}},"cell_type":"code","source":["y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4UjzpKTvEc2L","colab_type":"code","colab":{}},"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('elu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('elu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('elu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('elu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0002, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","from keras import metrics\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy', metrics.top_k_categorical_accuracy])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Fnlb5JCEc2d","colab_type":"code","outputId":"97288554-279b-4092-dbfe-95068f3a82c7","executionInfo":{"status":"ok","timestamp":1548979253880,"user_tz":300,"elapsed":2827052,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs, steps_per_epoch=1563,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Using real-time data augmentation.\n","Epoch 1/5\n","1563/1563 [==============================] - 599s 383ms/step - loss: 1.5925 - acc: 0.4281 - top_k_categorical_accuracy: 0.8911 - val_loss: 1.2183 - val_acc: 0.5781 - val_top_k_categorical_accuracy: 0.9476\n","Epoch 2/5\n","1563/1563 [==============================] - 599s 383ms/step - loss: 1.2775 - acc: 0.5514 - top_k_categorical_accuracy: 0.9436 - val_loss: 1.0737 - val_acc: 0.6181 - val_top_k_categorical_accuracy: 0.9632\n","Epoch 3/5\n","1563/1563 [==============================] - 596s 382ms/step - loss: 1.1567 - acc: 0.5977 - top_k_categorical_accuracy: 0.9546 - val_loss: 0.9765 - val_acc: 0.6659 - val_top_k_categorical_accuracy: 0.9685\n","Epoch 4/5\n","1563/1563 [==============================] - 596s 381ms/step - loss: 1.0809 - acc: 0.6242 - top_k_categorical_accuracy: 0.9616 - val_loss: 0.9746 - val_acc: 0.6594 - val_top_k_categorical_accuracy: 0.9701\n","Epoch 5/5\n","1563/1563 [==============================] - 596s 381ms/step - loss: 1.0335 - acc: 0.6427 - top_k_categorical_accuracy: 0.9651 - val_loss: 0.8654 - val_acc: 0.7039 - val_top_k_categorical_accuracy: 0.9750\n"],"name":"stdout"}]},{"metadata":{"id":"gyOPr5UcEc3B","colab_type":"code","outputId":"47ea3ce7-abb1-4d37-e33e-d93248abaa13","executionInfo":{"status":"ok","timestamp":1548979272135,"user_tz":300,"elapsed":18259,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# Save model and weights\n","# if not os.path.isdir(save_dir):\n","#     os.makedirs(save_dir)\n","# model_path = os.path.join(save_dir, model_name)\n","# model.save(model_path)\n","# print('Saved trained model at %s ' % model_path)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 18s 2ms/step\n","Test loss: 0.8654184688568115\n","Test accuracy: 0.7039\n"],"name":"stdout"}]}]}